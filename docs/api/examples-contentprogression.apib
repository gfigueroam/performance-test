FORMAT: 1A

# Content Progression

[scenario source](https://hmhco.slack.com/files/U07CMCTU1/F6SHY9X08/user-centric-content.pdf)

As a user reads content, page turn events are emitted to Apache Spark. When the Apache Spark worker detects an abnormally long pause between page turn events, it will assume the reader has stopped reading and will emit a message to UDS on the UDS Calculated Behavior Kafka queue.

# Requirements
Content Progression needs to be queried on a learning spine basis; each learning spine consists of upwards of a thousand skills or modules.

1. Ability to query for a user’s content progression within a given module
1. Ability to query for a user’s content progression across all modules within a content ID
1. Ability to query for a user’s content progression across all modules within a program
1. Teacher should be able to retrieve a student’s content progression


## UDS Calculated Behavior Kafka Messages
Each UDS Calculated Behavior message will have:
* `user` - the user affected by this message
* `key` - the key to use for this message
* `operation` - the operation to perform. One of: `increment`, `decrement`, `merge`, `set`.
* `data` - the value to use for `merge` and `set` operations.

## Processing Content Progression Events
 UDS will have a kafka consumer listening for these events which will call the appropriate API, `data.cb.<operation>`. UDS will model content progression as a hierarchical key with a common prefix `contentProgression-`. The key will then have a `learningSpineID` followed by `contentID`. The content progression for all modules within the same piece of content will be stored under the same UDS key. This object has one entry for each module whose value will be coordinates of the user's progression through the content (and any other desired metadata, such as a mastery score). To update or store content progression, the UDS kafka message's operation will be `merge`, and the UDS API call will be:

  `uds.data.cb.merge(user: <user>, key: "contentProgression-<learningSpineID>-<contentID>", data: {"module7": {"coords": {"page": 120}}})`

When a user first stores content progression, they will not have a value for the `contentProgression.<learningSpineID>.<contentID>` key; however the merge operation will behave as though the pre-existing value is `{}` and the resulting content progression will be

```
{
  "module7": {
    "coords": {
      "page": 120
    }
  }
}
```

If the user then proceeds to read to page 32 of module 8, the spark worker will emit the following message to UDS:
```
user: <user>,
key: "contentProgression.<learningSpineID>.<contentID>",
operation: "merge",
data: {"module8": {"coords": {"page": 32}}}
```

The UDS Kafka consumer will then place the following call to the UDS API:

  `uds.data.cb.merge(user: <user>, key: "contentProgression.<learningSpineID>.<contentID>", data: {"module8": {"coords": {"page": 32}}})`

The resulting content progression will be

```
{
  "module7": {
    "coords": {
      "page": 120
    }
  },
  "module8": {
    "coords": {
      "page": 32
    }
  }
}
```

## Querying A User's Content Progression for an entire learning spine
Using `data.cb.query`,
```
  uds.data.cb.query({
    user: <user>,
    keyPrefix: "contentProgression.<learningSpineID>"
  });

  Response:
  {
    "ok": true,
    "result": [
      "key": "contentProgression.<learningSpineID>.<contentID>",
      "data": {
        "module7": {
          "coords": {
            "page": 120
          }
        },
        "module8": {
          "coords": {
            "page": 32
          }
        }
      }
    ]
  }
```
